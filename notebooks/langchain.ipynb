{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from huggingface_hub import hf_hub_download\n",
    "import textwrap\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" You are going to be my assistant.\n",
    "Please try to give me the most beneficial answers to my\n",
    "question with reasoning for why they are correct.\n",
    "\n",
    " Question: {input} Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFaceHub(\n",
    "    repo_id=\"facebook/mbart-large-50\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.9,\n",
    "        \"max_length\": 200\n",
    "    },\n",
    "    huggingfacehub_api_token=HUGGING_FACE_API_KEY\n",
    ")\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/12_rules.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pages[200].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/embeddings/huggingface.py:46\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_embeddings \u001b[39m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m faiss_index \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_documents(pages, hf_embeddings, index_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m12_rules\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m results \u001b[39m=\u001b[39m faiss_index\u001b[39m.\u001b[39msearch(\u001b[39m\"\u001b[39m\u001b[39mHow many rules are there?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/embeddings/huggingface.py:49\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     50\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import sentence_transformers python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m sentence_transformers\u001b[39m.\u001b[39mSentenceTransformer(\n\u001b[1;32m     55\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, cache_folder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs\n\u001b[1;32m     56\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`."
     ]
    }
   ],
   "source": [
    "hf_embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "faiss_index = FAISS.from_documents(pages, hf_embeddings, index_name=\"12_rules\")\n",
    "\n",
    "results = faiss_index.search(\"How many rules are there?\")\n",
    "\n",
    "for result in results:\n",
    "    print(str(result.metadata[\"page\"]) + \":\", result.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
